# SIMD intrinsic

我们当然可以直接手写SIMD的汇编指令，但没必要。编译器提供了一些几乎能直接映射到汇编的intrinsic函数，抽象层次稍微高一点，比如我们不用关心寄存器如何分配。

我们在C里只要`#include<immintrin.h>`就可以使用所有的SIMD intrinsic函数了。在rust中，x86的intrinsic函数则放在`core::arch::x86_64`中（都假定是64位系统了）。

## 数据类型

目前x86(x86-64)下的SIMD数据类型有以下这些，都对应着对应位数的寄存器：

* `__m64`: 表示1个64位整数，2个32位整数，4个16位整数或8个8位整数
* `__m128`: 表示4个单精度浮点数
* `__m128d`: 表示2个双精度浮点数（d是double，双精度的意思）
* `__m128i`：2个64位整数，4个32位整数，8个16位整数，16个8位整数。（i是integer，整数的意思）
* `__m256`: 表示8个单精度浮点数
* `__m256d`: 表示4个双精度浮点数
* `__m256i`: 4个64位整数blahblah...
* `__m512`, `__m512d`, `__m512i`: 同理
* `__m128bh`, `__m256bh`, `__m512bh`: 半精度浮点数的SIMD类型（bh是brain floating point）

比如说`__m256`的内存布局和`float[8]`或者说`[f32;8]`是一致的（只是对齐不一样），长这样，其中每个格子是为32位，为单精度浮点数：

```text
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  a7   │  a6   │  a5   │  a4   │  a3   │  a2   │  a1   │  a0   │ 
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
     7       6       5       4       3       2       1       0   
```

为了方便与整数的高低位对应，这里也把低位放在右边。（一般书写顺序整数的位数由低到高也是从右到左，有点rtl文字的意味了）



注意，`__m128`的对齐为16个字节，`__m256`对齐为32个字节，`__m512`对齐为64个字节，而`malloc`函数分配的内存则按`size_t`的对齐（一般为8字节），所以如果要分配这些类型的内存则需要`aligned_alloc`函数。



## 函数

所有的intrinsic函数可以在 [Intel Intrinsics Guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)查到，不过你会看到一大堆长这样的函数`_mm256_add_epi32`, `_mm256_cvtepi32_ps`，第一眼会很懵逼。但这里的大多数函数都遵循一个命名规则：`_mm<bit_width>_<op_name>_<data_ty>`

1. bit_width：表示这个函数作用在多少位的向量上，比如`_mm256`则表示作用于256位的向量上。如果没标则默认是128位的。
2. op_name：则是操作的名字，比如说`add`是加，`cvt`是转换，`load`是从内存加载等等。
3. data_ty：表示向量中的数据类型是什么，比如`pd`是双精度浮点，`ps`是单精度浮点，`epi32`是32位有符号整数，`epu64`是64位有符号整数等等。



这些intrinsic函数又可以分为几类：算术类，逻辑类，分量操作类，比较类，转换类，内存读写类，掩码类（AVX512专属）。我们来展开一下。



## 算术类/逻辑类

算术类和逻辑类属于是最简单典型的操作了，大部分都很好理解，比如`_mm256_mul_ps`就是`__m256`中8个单精度浮点数同时相乘：

```text
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  a7   │  a6   │  a5   │  a4   │  a3   │  a2   │  a1   │  a0   │   a
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                 *
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  b7   │  b6   │  b5   │  b4   │  b3   │  b2   │  b1   │  b0   │   b
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                 =
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │ a7*b7 │ a6*b6 │ a5*b5 │ a4*b4 │ a3*b3 │ a2*b2 │ a1*b1 │ a0*b0 │  _mm256_mul_ps(a, b)
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
```

而`_mm256_and_ps`顾名思义，就是`_mm256_mul_ps`中8个单精度浮点数同时逻辑与了。不过我们可以关注一下这些指令的延迟和吞吐，比如说`_mm256_mul_ps`在Intel Intrinsics guide中上说在Icelake架构中，延迟是4（这里单位我不太清楚），吞吐量（CPI）为0.5——也就是每条指令只需要0.5个指令周期就能完成。



这里额外介绍一个也很常用的运算，融合乘加，一个指令同时完成乘法和加法。比如`_mm256_fmadd_ps`接受三个`__m256`向量`a`, `b`, `c`，每个分量上同时进行`a[i] * b[i] + c[i]`运算：

```text
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  a7   │  a6   │  a5   │  a4   │  a3   │  a2   │  a1   │  a0   │   a
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                 *
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  b7   │  b6   │  b5   │  b4   │  b3   │  b2   │  b1   │  b0   │   b
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                 +
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  c7   │  c6   │  c5   │  c4   │  c3   │  c2   │  c1   │  c0   │   c
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                 =
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │ a7*b7 │ a6*b6 │ a5*b5 │ a4*b4 │ a3*b3 │ a2*b2 │ a1*b1 │ a0*b0 │  _mm256_fmadd_ps(a, b, c)
 │  +c7  │  +c6  │  +c5  │  +c4  │  +c3  │  +c2  │  +c1  │  +c0  │
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
```

但其实这和`_mm256_mul_ps`具有同样的延迟和吞吐，而且这是一个操作，会比分别乘完再加少一次舍入误差——会更加精确。



算术类除了加减乘除，其实还有一些数学函数，比如`sqrt`/三角函数啥的（竟然把这些都做进了电路里，真狠啊）。还有一些不是按对应分量的运算，比如说水平加法`hadd`，点乘`dp`等等。这里便不展开了。



## 分量操作类

分量操作类，顾名思义就是用来操作向量中的分量的，比如说分量位置的移动，分量的读取修改等。这也是SIMD中十分重要的一种运算。其中最常用的操作是`permute`排列操作，排列操作也有很多种。

最通用的排列是`permutexvar`(AVX512引入)操作，比如`_m256_permutexvar_ps`操作，接受一个idx向量，和一个被排列向量，每个分量进行索引操作`a[ix]`操作：

```text
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  i7   │  i6   │  i5   │  i4   │  i3   │  i2   │  i1   │  i0   │   idx
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                []
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  a7   │  a6   │  a5   │  a4   │  a3   │  a2   │  a1   │  a0   │   a
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                 =
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │ a[i7] │ a[i6] │ a[i5] │ a[i4] │ a[i3] │ a[i2] │ a[i1] │ a[i0] │  _m256_permutexvar_ps(idx, a)
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
```

这个在Icelake架构下延迟为3，CPI为1，吞吐量要比乘法加法要低一些。

除了`permutexvar`这些名字里带var的操作（即用向量本身做索引）以外，还有些不带var的`permute`操作，通过一个8位的**常量**来表示索引向量，比如`_mm_permute_ps(a, 0b11_01_01_10)`：

```text
┌───────┬───────┬───────┬───────┐ 
│  a3   │  a2   │  a1   │  a0   │   a
└───────┴───────┴───────┴───────┘ 
   11      01      01       10
┌───────┬───────┬───────┬───────┐ 
│ a[3]  │ a[1]  │ a[1]  │ a[2]  │   _mm_permute_ps(a, 0b11_01_01_10)
└───────┴───────┴───────┴───────┘
```

这个操作在Icelake架构中，延迟只有1，比上面的`permutexvar`快不少。但这种操作挺弱鸡，只能在128位的数据内进行排序——在AVX里有128位的通道（lane）和256位的通道，在一个通道中排列的效率会更高（再补充一点，`permutexvar`里的`x`是across，也就是跨通道的意思）。如果在超过一个128位通道的向量中进行排列，相当于分别对每个128位的部分都进行同样的操作，比如说`_mm256_permute_ps(a, 0b11_01_01_10)`：

```text
┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
│  a7   │  a6   │  a5   │  a4   │  a3   │  a2   │  a1   │  a0   │   a
└───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                   11      01      01       10
┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
│  a[7] │  a[5] │  a[5] │  a[6] │ a[3]  │ a[1]  │ a[1]  │ a[2]  │   _mm256_permute_ps(a, 0b11_01_01_10)
└───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘
注意这里下标+4了，也就是0b100
```



除了`permute`以外，还有其它操作，比如`shuffle`/`blend`操作，这里就不一一展开了。



## 比较类

比较的操作也是比较直观的，就是在每个分量上进行比较，如果为true分量上为全1，为false则分量为0。

举个具体的例子，`_mm256_cmp_ps(a, b, _CMP_LE_UQ)`，其中第三个参数是个常量，表示比较的操作，其中`U`表示不比较`nan`（如果要比较的话用`O`），而`Q`表示quiet（如果关心signal浮点数的话则用`S`）。其它比较运算可以看intel Intrinsics guide。

```text
┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
│  1.0  │  2.0  │  3.0  │  4.0  │  5.0  │  6.0  │  7.0  │  8.0  │   a
└───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                      _CMP_LE_UQ 也就是 <=
┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
│  4.0  │  4.0  │  4.0  │  4.0  │  4.0  │  4.0  │  4.0  │  4.0  │   b
└───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                =
┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
│  0x0  │  0x0  │  0x0  │  0x0  │0xFFFF │0xFFFF │0xFFFF │0xFFFF │   _mm256_cmp_ps(a, b, _CMP_LE_UQ)
│       │       │       │       │  FFFF │  FFFF │  FFFF │  FFFF │
└───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
```



比较运算看起来比较简单，但是如果结合逻辑运算的话，就可以实现类似if-else的效果。举个例子，如果我们想在分量上计算：

```rust
let d = if a <= b {
    a + b
} else {
    a * b
}
```

我们就可以写成这样：

```rust
// 假设结果是这个
// ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
// │  true │  true │  true │  true │ false │ false │ false │ false │  
// └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘  
let cmp = _mm256_cmp_ps(a, b, _CMP_LE_UQ);

// 加完后将为false的给置0
// ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
// │ a7+b7 │ a6+b6 │ a5+b5 │ a4+b4 │   0   │   0   │   0   │   0   │  
// └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘  
let add = __mm256_and_ps(cmp, _mm256_add_ps(a, b));

// 加完后将为true的置0
// ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
// │   0   │   0   │   0   │   0   │ a3*b3 │ a2*b2 │ a1*b1 │ a0*b0 │  
// └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘  
let mul = __mm256_notand_ps(cmp, _mm256_mul_ps(a, b));

// 最后将结果合并
// ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
// │ a7+b7 │ a6+b6 │ a5+b5 │ a4+b4 │ a3*b3 │ a2*b2 │ a1*b1 │ a0*b0 │  
// └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘  
let res = __mm256_or_ps(add, mul);
```

虽然这里会产生多余的运算，把不必要计算的分量都计算了一遍，但这里不产生实际的分支，对分支预测十分友好，最终还是快的。

那有没有不进行额外计算的办法呢？有！AVX-512里就引入了这样的方式！



## 掩码类

AVX512的新指令里引入的掩码的概念，堪称神来之笔，为向量计算的表达力提升了一个台阶。目前分别为8位、16位、32位、64位的掩码`__mask8`, `__mask16`,`__mask32`, `__mask64`。掩码的每一位都映射到向量中的一个分量，一般来说0代表对应分量不参与运算，1代表对应分量参与运算。

比如说`_m256_mask_add_ps`，接受3个向量`src`, `a`, `b`，其中`a`和`b`两个向量参与运算。当掩码对应位为0时，*不*进行运算，取`src`对应位，而当掩码对应位为1时，才进行运算：（注意，这里的掩码并不是常量）

```text
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  s7   │  s6   │  s5   │  s4   │  s3   │  s2   │  s1   │  s0   │   src
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
     1       1       1       1       0       0       0      0        mask = 0b11110000
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  a7   │  a6   │  a5   │  a4   │  a3   │  a2   │  a1   │  a0   │   a
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                 +
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │  b7   │  b6   │  b5   │  b4   │  b3   │  b2   │  b1   │  b0   │   b
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                 =
 ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
 │ a7+b7 │ a6+b6 │ a5+b5 │ a4+b4 │  s3   │  s2   │  s1   │  s0   │   _m256_mask_add_ps(src, mask, a, b)
 └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘  
 
 如果想把不参与运算的分量置0，那还能把`mask`换成`maskz`，z就是zero的意思。
```



而AVX512中比较操作也返回一个掩码，而非一整个向量了，照搬之前的例子`_mm256_cmp_ps_mask(a, b, _CMP_LE_UQ)`：

```text
┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
│  1.0  │  2.0  │  3.0  │  4.0  │  5.0  │  6.0  │  7.0  │  8.0  │   a
└───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                      _CMP_LE_UQ 也就是 <=
┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
│  4.0  │  4.0  │  4.0  │  4.0  │  4.0  │  4.0  │  4.0  │  4.0  │   b
└───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
                                =
    1       1       1       1       0       0       0       0       _mm256_cmp_ps_mask(a, b, _CMP_LE_UQ) = 0b11110000
```

得到的mask又可以放到mask运算中去。我们可以用AVX512来重新写一下刚刚模拟if-else的例子：

```rust
// 0b11110000
let cmp_mask = _mm256_cmp_ps_mask(a, b, _CMP_LE_UQ);

// 只在掩码为1的分量上计算加法
// ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
// │ a7+b7 │ a6+b6 │ a5+b5 │ a4+b4 │  a3   │  a2   │  a1   │  a0   │  
// └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘  
let add = __mm256_maskz_add_ps(a, cmp_mask, a, b);

// 在掩码为0的分量上计算乘法
// ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
// │ a7+b7 │ a6+b6 │ a5+b5 │ a4+b4 │ a3*b3 │ a2*b2 │ a1*b1 │ a0*b0 │  
// └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘  
let res = __mm256_maskz_mul_ps(add, !cmp_mask, a, b);
```

用上了mask运算之后，除了减少了三次向量逻辑运算，同时一个mask指令里面还减少不必要的运算。



有了掩码操作之后，化简了特别多的操作，在这里就不一一展开了（留一个到内存读写）。**所以说AVX512 YYDS!!!!在此diss一下某牙膏厂**



## 转换类

这里就展开不介绍了，反正就是分量数据类型的转换，操作名一般为`cvt`。



## 内存读写类

最后再来展开一下内存读写相关的操作。最基础的读写操作就是`loadu`和`storeu`，从某个地址中读出或写入数据，这里u指的是unaligned，也就是不要求读出和写入的内存是对齐的——因为在新架构中，对不对齐已经不影响效率了。

比如说`__m256 _m256_loadu_ps(float const * mem_addr)`，就是从`mem_addr`的地址开始**连续**读8个float——**注意：这里要求这篇连续的内存区域是合法的，否则就是UB**。`_m256_storeu_ps`也类似。

不过很多时候，申请的内存并不都是16, 32, 64bytes的倍数，不一定能很好地被向量所“覆盖”，于是当我们想读入或者写入剩下几个字节的时候就会很麻烦（就得逐个读到向量中）。那有什么办法呢——**答案还是AVX512！** AVX512提供了两个神操作`expendloadu`和`compressstoreu`，搭配掩码就可以做到内存按向量分量部分读入和写入。

举个例子：

```rust
// 这里只有7个f32，不能直接load到_m256中
let mut arr: [f32; 7] = array_fn(|i| i as f32);

// 但我们可以通过expendloadu只读低位7个f32到向量中，剩下一个分量置为0
// ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
// │  0.0  │  6.0  │  5.0  │  4.0  │  3.0  │  2.0  │  1.0  │  0.0  │   v
// └───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
let v = _m256_maskz_expandloadu_ps(0b01111111, addr_of!(arr).cast());

// 只将向量中7个数（除了第5个分量）写入`arr`中
// ┌───────┬───────┬───────┬───────┬───────┬───────┬───────┐ 
// │  0.0  │  6.0  │  5.0  │  3.0  │  2.0  │  1.0  │  0.0  │   arr
// └───────┴───────┴───────┴───────┴───────┴───────┴───────┘ 
_m256_mask_compressstoreu_ps(addr_mut_of!(arr).cast(), 0b11101111, v);


```



除了`load`和`store`，还介绍几个：

1. `broadcast`操作，把所有分量都置为一个值（参数）
2. `insert`操作，当然也可以直接`a[i] = x`
3. `extract`操作，也可以直接通过`a[i]`读
4. `gather`操作，可以离散地读内存里的值，但不太好用。



最后还要注意一点，这些内存读写操作都还是蛮贵的，比如一个`_mm256_loadu_ps`在Icelake架构里延迟都要去到8——所以尽量还是减少内存的读写，更多地使用SIMD给的类型。

